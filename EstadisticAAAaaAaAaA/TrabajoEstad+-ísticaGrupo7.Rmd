---
title: "EDA: Steam"
author: "Grupo7"
date: "2024-09-24"

output: 
  html_document:
    toc: yes
    toc_float: yes

---




```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,          
  message = FALSE,      # Oculta mensajes (como los de carga de paquetes)
  warning = FALSE       # Oculta advertencias (warnings)
)

```


# 1. Introducción y definición de objetivos

Mediante el estudio estadístico de datos obtenidos sobre los juegos publicados en la plataforma de Steam desde 2005, se pretende conocer y analizar si es posible establecer alguna relación entre las diversas variables que se toman en cuenta en dicho estudio (año de lanzamiento, puntuación media de usarios, etc.).

Al disponer de variables enlazadas directamente a la acogida por parte del público de los diversos títulos de Steam, el principal propósito de esta investigación es llevar a cabo un estudio de mercado sobre los mismos. De este modo, se analizaría si es posible establecer una conexión directa entre la satisfacción del público y otras variables como podrían ser la duración o los tags. Esta última podría resultar sumamente interesante puesto que sería posible explorar las tendencias de los usuarios a la hora de puntuar juegos de determinados géneros o categorías, profundizando así más allá de los aspectos técnicos del videojuego (como el tiempo de contenido), en lo que el usuario busca experimentar sensorial, emocional o psicológicamente a la hora de decidir qué jugar. Asimismo, dado que las valoraciones profesionales no tienen por qué coincidir con las de los usuarios, también sería de interés estudiar cómo difieren entre sí.

Por otro lado, también se pretende llevar a cabo un análisis sobre los propios desarrolladores, descubriendo así cuáles son los géneros que tienen más lanzamientos cada año y si es posible establecer una relación con las valoraciones de lanzamientos del mismo género de años anteriores.

Precisamente debido a los objetivos de este estudio estadístico, se ha decidido no analizar las variables 'positivity_ratio' y 'extra_content_length', ya que no son relevantes en relación al análisis de otras variables ni tampoco por sí mismas.

# 2. Importación de datos y carga de paquetes


```{r}
library(tidyverse)
library(summarytools)
library(GGally)
library(gt)
library(flextable)
library(knitr)
library(corrplot)
library(kableExtra)
library(ggplot2)
library(tidyr)
library(dplyr)
library(psych)

```


```{r}
#Lee el dataset al que hemos llamado datos
datos <- readxl::read_excel("dataset.xlsx") 

```
              
# 3. Diccionario de datos

* `id`: Identificador del juego (identificador)
* `name`: Nombre del juego (identificador)
* `year`: Año de salida al mercado (numérica discreta)
* `metacritic_rating`: Nota media de valoración profesional (numérica discreta, valor sobre 100)
* `reviewer_rating`: Nota media de la valoración de los usuarios   (numérica discreta, sobre 10)
* `positivity_ratio`: Ratio de positividad, cociente entre las Valoraciones positivas y las valoraciones negativas (numérica continua)
* `to_beat_main`: Tiempo medio necesario para superar el juego principal (numérica continua, medida en horas)
* `to_beat_extra`: Tiempo medio necesario para superar el juego principal y contenido extra (numérica continua, medida en horas)
* `to_beat_completionist`: Tiempo medio para completar todo el contenido del juego y obtener todo sus logros (numérica continua, medida en horas)
* `extra_content_length`: Diferencia de tiempo entre el contenido principal y el extra (numérica continua, medida en horas)
* `tags`: Categorías o "tags" bajo las que se encuentra inscrito cada juego (categórica multinivel)

# 4. Análisis exploratorio de datos

El estudio de este dataset constará de dos partes, siendo la primera un análisis univariante de las variables de las que dispone este dataset, sin incluir aquellas que se ha explicado con anterioridad que no son de interés.

## 4.1. Datos univariantes

### 4.1.1. Variable 'year'
Tabla de frequencias de los años en intervalos de 5 en 5 años.
```{r}

Años <- cut(datos$year, breaks = 6)  # Definimos 6 intervalos

# Crea la tabla de frecuencias 
tabla_frecuencias2 <- as.data.frame(table(Años))

# Calcula la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Muestra la tabla con formato
knitr::kable(tabla_frecuencias2, digits = 4)

```
Gráfico de barras y resumen numérico para una mejor visualización de la cantidad de juegos subidos a Steam en cada año.

```{r}
datos |> 
  # Inicia la visualización 
  ggplot(aes(x = year)) +
  # Añade un gráfico de barras, rellenando las barras
  geom_bar(fill = "skyblue") +
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Juegos por año", 
       x = "Año de salida (2005-2023)",
       y = "Cantidad de juegos")
      
```

```{r}
datos |> descr(year)
```

Se observa como la producción de los videojuegos lleva en auge las últimas décadas, haciendo un salto en 2015, además de cómo se frenó la caída de la industria en el año 2020 debido a la pandemia mundial y a la cuarentena. 

### 4.1.2. Variable 'metacritic_rating'
Tabla de frecuencias de las críticas de expertos divididas en 7 intervalos:
```{r}

# Remueve NA's de los datos 
datos_limpios <- datos %>%
  filter(!is.na(metacritic_rating))

# Define los intervalos manualmente para que no haya valores que se salgan de los mínimos y máximos
breaks <- seq(20, max(datos_limpios$metacritic_rating, na.rm = TRUE), length.out = 8)  # 7 intervalos

# Corta los datos en los intervalos especificados
metacritic_rating <- cut(datos_limpios$metacritic_rating, breaks = breaks)

# Crea la tabla de frecuencias
tabla_frecuencias2 <- as.data.frame(table(metacritic_rating))

# Calcula las frecuencias relativas y acumuladas
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Muestra la tabla con formato
knitr::kable(tabla_frecuencias2, digits = 4)

```
Gráfico de barras:
```{r}
datos |> 
  # Inicia una visualización
  ggplot(aes(x = metacritic_rating)) +
  # Añade un gráfico de barras, rellenando las barras 
  geom_bar(fill = "skyblue") +
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Puntuación del crítico", 
       x = "Puntuación (0-100)",
       y = "Frecuencia absoluta") +
   scale_x_continuous(breaks = seq(20, 100, by = 10))  # Define más marcas en el eje X cada 10 unidades
      
```

En este gráfico se observa que las puntuaciones más frecuentes se encuentran entre los 60 y 85 puntos. La puntuación más frecuente, es decir, la moda, son 80 puntos, llegando a una frecuencia de casi 200.

```{r}
summary(datos$metacritic_rating)

```

La información se amplía con este resumen en el que se destaca que la puntuación media son 72,84 puntos. La nota más baja son 20 puntos y la más alta 97 puntos. Se concluye, entonces, que no hay ningún juego que tenga una puntuación de 100.



### 4.1.3.Variable 'reviewer_rating'
Tabla de frecuencias por cada valor:
```{r}
# Crea una tabla de frecuencias
tabla_frecuencias2 <- as.data.frame(table(datos$reviewer_rating))

# Calcula la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

#Muestra la tabla con formato
knitr::kable(tabla_frecuencias2, digits = 4)
```

Gráfico de barras:
```{r}
datos |> 
  # Inicia una visualización 
  ggplot(aes(x = reviewer_rating)) +
  # Añade un gráfico de barras, rellenando las barras 
   geom_bar(fill = "skyblue") +
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Puntuación del jugador", 
       x = "Puntuación (0-10)",
       y = "Frecuencia absoluta") +
  scale_x_continuous(breaks = seq(0, 10, by = 1))  # Define más marcas en el eje X cada unidad
```

En este gráfico se observa que las puntuaciones más frecuentes se encuentran entre los 5 y 8 puntos. La puntuación más frecuente, es decir, la moda, son 8 puntos, seguido muy de cerca por los 5 puntos. 

```{r}
summary(datos$reviewer_rating)
```

La información se amplía con este resumen en el que se destaca que la puntuación media son 6,14 puntos. La nota más baja es 1 punto, algo que en el gráfico no se aprecia con claridad. La más alta son 9 puntos. Al igual que en las metacritic ratings, no hay ningún juego con una puntuación de 10.

### 4.1.4. Variable 'to_beat_main'
Tabla de frecuencias dividida en 10 intervalos:
```{r}

# Definir intervalos
Tiempo <- cut(datos_limpios$to_beat_main, breaks = 10)  # Definimos intervalos

# Crea la tabla de frecuencias
tabla_frecuencias2 <- as.data.frame(table(Tiempo))

# Calcular la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Mostrar la tabla con formato usando knitr::kable
knitr::kable(tabla_frecuencias2, digits = 4, 
             caption = "Valores de 'to_beat_main'")


```

Como en la tabla de frecuencias no se apreciaban bien los intervalos debido a la inmensa cantidad de valores, se ha seleccionado un rango de 0 a 50 horas, que es donde se encuentran la mayoría de valores.

```{r}

# Truncar los valores mayores a 50
datos$to_beat_main <- ifelse(datos$to_beat_main > 50, 51, datos$to_beat_main)

# Crear las etiquetas personalizadas para los intervalos
etiquetas_intervalos <- c(paste0("[", seq(0, 45, by = 5), ", ", seq(5, 50, by = 5), ")"), "Más de 50")

# Definir los intervalos en el rango de 0 a 50 horas, más un intervalo adicional para valores mayores a 50
Tiempo <- cut(datos$to_beat_main, 
              breaks = c(seq(0, 50, length.out = 11), Inf),   # Inf para incluir valores mayores a 50
              labels = etiquetas_intervalos, 
              right = FALSE)  # Intervalos cerrados a la izquierda y abiertos a la derecha

# Crear la tabla de frecuencias
tabla_frecuencias2 <- as.data.frame(table(Tiempo))

# Calcular la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Mostrar la tabla con formato usando knitr::kable
knitr::kable(tabla_frecuencias2, digits = 4, 
             caption = "'to_beat_main'")


```

A continuación el gráfico de densidad de 'to_beat_main' sin agrupar datos:
```{r density_plot1, echo=TRUE}
# Filtrar los datos para eliminar valores NA
datos_filtrados <- datos %>%
  filter(!is.na(to_beat_main))

# Crear el gráfico de densidad
ggplot(datos_filtrados, aes(x = to_beat_main)) +
  geom_density(fill = "skyblue", color = "coral1", alpha = 0.6) +
  labs(title = "Distribución del Tiempo para Completar el Juego Principal",
       x = "Tiempo para Completar el Juego Principal (horas)",
       y = "Densidad") +
  theme_minimal()
```

Dado que la existencia de muy pocos datos con valores muy grandes dificulta el análisis del gráfico de densidad, se ha optado por hacer otro gráfico de densidad agrupando los datos más grandes, a partir de 50 horas, en un mismo valor. De este modo, es posible analizar con mayor precisión los datos en este rango de 0 a 50 horas, que es donde se encuentran la mayoría de ellos. Al aplicar este cambio, se obtiene el siguiente gráfico de densidad:

```{r density_plot_grouped_extra1, echo=TRUE}
# Filtrar los datos para eliminar valores NA
datos_filtrados_main <- datos %>%
  filter(!is.na(to_beat_main))

# Agrupar valores mayores a 50 horas en una nueva categoría
datos_filtrados_main <- datos_filtrados_main %>%
  mutate(to_beat_main_grouped = ifelse(to_beat_main > 50, 50, to_beat_main))

# Crear el gráfico de densidad usando la variable agrupada
ggplot(datos_filtrados_main, aes(x = to_beat_main_grouped)) +
  geom_density(fill = "skyblue", color = "coral1", alpha = 0.6) +
  labs(title = "Distribución del Tiempo para Completar el Juego Principal (Agrupando > 50h)",
       x = "Tiempo para Completar el Juego Principal (horas)",
       y = "Densidad") +
  theme_minimal() +
  scale_x_continuous(breaks = c(seq(0, 50, by = 10)), labels = c(seq(0, 40, by = 10), "50+"))

```

A partir de estos dos gráficos, entonces, es posible establecer una clara predominancia de juegos cuyo contenido principal tan solo requieren entre 0 y 4 horas para completarse, con un pico claro en unas 2 horas. A partir de las 4 horas, la densidad de juegos no hace más que decrecer a medida que aumenta la variable del tiempo, con un leve pico en 15 horas. Ciertamente, en este último gráfico se puede observar que la densidad vuelve a crecer a partir de 47 aproximadamente, pero eso se debe a la agrupación de esos datos cuyo tiempo es mayor a 50. No obstante, si se observa con detenimiento el primer gráfico de densidad, se observa que en realidad, la densidad de juegos a partir de las 50 horas se mantiene bastante estable.

A continuación, el resumen estadístico de la variable to_beat_main:
```{r summary_to_beat_main, echo=TRUE}
summary(datos$to_beat_main)
```
La información se amplía y precisa con este resumen en el que se destaca que el tiempo medio es de 9,49 horas. El tiempo más bajo es de 0,01 horas, algo que en el gráfico no se aprecia con claridad debido al valor tan pequeño que representa. El más alto es de 2105,84 horas. Por otro lado, la mediana se encuentra en las 4 horas.

### 4.1.5. Variable 'to_beat_extra'
Tabla de frecuencias con 10 intervalos:
```{r}

Tiempo <- cut(datos$to_beat_extra, breaks = 10)  # Definimos intervalos

# Crea la tabla de frecuencias 
tabla_frecuencias2 <- as.data.frame(table(Tiempo))

# Calcula la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Mostrar la tabla con formato usando knitr::kable
knitr::kable(tabla_frecuencias2, digits = 4, 
             caption = "'Valores de to_beat_extra'")
```

Como en la tabla de frecuencias no se apreciaban bien los intervalos debido a la inmensa cantidad de valores, se ha seleccionado un rango de 0 a 50 horas, que es donde se encuentran la mayoría de valores.

```{r}

# Truncar los valores mayores a 50
datos$to_beat_extra <- ifelse(datos$to_beat_extra > 50, 51, datos$to_beat_extra)

# Definir los intervalos en el rango de 0 a 50 horas, más un intervalo adicional para valores mayores a 50
Tiempo <- cut(datos$to_beat_extra, 
              breaks = c(seq(0, 50, length.out = 11), Inf),   # Inf para incluir valores mayores a 50
              labels = etiquetas_intervalos, 
              right = FALSE)  # Intervalos cerrados a la izquierda y abiertos a la derecha

# Crea la tabla de frecuencias
tabla_frecuencias2 <- as.data.frame(table(Tiempo))

# Calcula la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Mostrar la tabla con formato usando knitr::kable
knitr::kable(tabla_frecuencias2, digits = 4, 
             caption = "'to_beat_extra'")


```

A continuación el gráfico de densidad de 'to_beat_extra' sin agrupar datos:
```{r density_plot2, echo=TRUE}
# Filtrar los datos para eliminar valores NA
datos_filtrados <- datos %>%
  filter(!is.na(to_beat_extra))

# Crear el gráfico de densidad
ggplot(datos_filtrados, aes(x = to_beat_extra)) +
  geom_density(fill = "skyblue", color = "coral1", alpha = 0.6) +
  labs(title = "Distribución del Tiempo para Completar el Juego Principal y su Contenido Extra",
       x = "Tiempo para Completar el Juego Principal y su Contenido Extra (horas)",
       y = "Densidad") +
  theme_minimal()
```

Dado que la existencia de muy pocos datos con valores muy grandes dificulta el análisis del gráfico de densidad, se ha optado por hacer otro gráfico de densidad agrupando los datos más grandes, a partir de 50 horas, en un mismo valor. De este modo, es posible analizar con mayor precisión los datos en este rango de 0 a 50 horas, que es donde se encuentran la mayoría de ellos. Al aplicar este cambio, se obtiene el siguiente gráfico de densidad:

```{r density_plot_grouped_extra2, echo=TRUE}
# Filtrar los datos para eliminar valores NA
datos_filtrados_extra <- datos %>%
  filter(!is.na(to_beat_extra))

# Agrupar valores mayores a 50 horas en una nueva categoría
datos_filtrados_extra <- datos_filtrados_extra %>%
  mutate(to_beat_extra_grouped = ifelse(to_beat_extra > 50, 50, to_beat_extra))

# Crear el gráfico de densidad usando la variable agrupada
ggplot(datos_filtrados_extra, aes(x = to_beat_extra_grouped)) +
  geom_density(fill = "skyblue", color = "coral1", alpha = 0.6) +
  labs(title = "Distribución del Tiempo para Completar el Juego Principal y Contenido Extra (Agrupando > 50h)",
       x = "Tiempo para Completar el Juego Principal y Contenido Extra (horas)",
       y = "Densidad") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10)) +  # Ajuste del tamaño del título
  scale_x_continuous(breaks = c(seq(0, 50, by = 10)), labels = c(seq(0, 40, by = 10), "50+"))


```

A partir de estos dos gráficos, entonces, es posible establecer una clara predominancia de juegos cuyo contenido principal y extras tan solo requieren entre 0 y 10 horas para completarse, con un pico claro en unas 3 horas. A partir de las 10 horas, la densidad de juegos no hace más que decrecer a medida que aumenta la variable del tiempo, con un leve pico en 20 horas. Ciertamente, en este último gráfico se puede observar que la densidad vuelve a crecer a partir de 47 aproximadamente, pero eso se debe a la agrupación de esos datos cuyo tiempo es mayor a 50. No obstante, si se observa con detenimiento el primer gráfico de densidad, se observa que en realidad, la densidad de juegos a partir de las 50 horas se mantiene bastante estable.

A continuación, el resumen estadístico de la variable to_beat_extra:
```{r summary_to_beat_extra, echo=TRUE}
summary(datos$to_beat_extra)
```
La información se amplía y precisa con este resumen en el que se destaca que el tiempo medio es de 20 horas. El tiempo más bajo es de 0,03 horas, algo que en el gráfico no se aprecia con claridad debido al valor tan pequeño que representa. El más alto es de 6500 horas. Por otro lado, la mediana se encuentra en las 7,5 horas.

### 4.1.6. Variable 'to_beat_completionist'
Tabla de frecuencia con 10 intervalos:
```{r}

Tiempo <- cut(datos$to_beat_completionist, breaks = 10)  # Definimos intervalos

# Crea la tabla de frecuencias 
tabla_frecuencias2 <- as.data.frame(table(Tiempo))

# Calcula la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Mostrar la tabla con formato usando knitr::kable
knitr::kable(tabla_frecuencias2, digits = 4, 
             caption = "'Valores de to_beat_completionist'")
```
Como en la tabla de frecuencias no se apreciaban bien los intervalos debido a la inmensa cantidad de valores, se ha seleccionado un rango de 0 a 50 horas, que es donde se encuentran la mayoría de valores.

```{r}

# Truncar los valores mayores a 50
datos$to_beat_completionist <- ifelse(datos$to_beat_completionist > 50, 51, datos$to_beat_completionist)

# Definir los intervalos en el rango de 0 a 50 horas, más un intervalo adicional para valores mayores a 50
Tiempo <- cut(datos$to_beat_completionist, 
              breaks = c(seq(0, 50, length.out = 11), Inf),   # Inf para incluir valores mayores a 50
              labels = etiquetas_intervalos, 
              right = FALSE)  # Intervalos cerrados a la izquierda y abiertos a la derecha

# Crea la tabla de frecuencias
tabla_frecuencias2 <- as.data.frame(table(Tiempo))

# Calcula la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Mostrar la tabla con formato usando knitr::kable
knitr::kable(tabla_frecuencias2, digits = 4, 
             caption = "'to_beat_completionist'")


```

A continuación el gráfico de densidad de 'to_beat_completionist' sin agrupar datos:
```{r density_plot3, echo=TRUE}
# Filtrar los datos para eliminar valores NA
datos_filtrados <- datos %>%
  filter(!is.na(to_beat_completionist))

# Crear el gráfico de densidad
ggplot(datos_filtrados, aes(x = to_beat_completionist)) +
  geom_density(fill = "skyblue", color = "coral1", alpha = 0.6) +
  labs(title = "Distribución del Tiempo para Completar Todo el Contenido",
       x = "Tiempo para Completar Todo el Contenido",
       y = "Densidad") +
  theme_minimal()
```

Dado que la existencia de muy pocos datos con valores muy grandes dificulta el análisis del gráfico de densidad, se ha optado por hacer otro gráfico de densidad agrupando los datos más grandes, a partir de 50 horas, en un mismo valor. De este modo, es posible analizar con mayor precisión los datos en este rango de 0 a 50 horas, que es donde se encuentran la mayoría de ellos. Al aplicar este cambio, se obtiene el siguiente gráfico de densidad:

```{r density_plot_grouped_extra3, echo=TRUE}
# Filtrar los datos para eliminar valores NA
datos_filtrados_completionist <- datos %>%
  filter(!is.na(to_beat_completionist))

# Agrupar valores mayores a 50 horas en una nueva categoría
datos_filtrados_completionist <- datos_filtrados_completionist %>%
  mutate(to_beat_completionist_grouped = ifelse(to_beat_completionist > 50, 50, to_beat_completionist))

# Crear el gráfico de densidad usando la variable agrupada
ggplot(datos_filtrados_completionist, aes(x = to_beat_completionist_grouped)) +
  geom_density(fill = "skyblue", color = "coral1", alpha = 0.6) +
  labs(title = "Distribución del Tiempo para Completar Todo el Contenido (Agrupando > 50h)",
       x = "Tiempo para Completar Todo el Contenido (horas)",
       y = "Densidad") +
  theme_minimal() +
  scale_x_continuous(breaks = c(seq(0, 50, by = 10)), labels = c(seq(0, 40, by = 10), "50+"))

```

A partir de estos dos gráficos, entonces, es posible establecer una clara predominancia de juegos cuyo contenido completo tan solo requieren entre 0 y 7,5 horas para completarse, con un pico claro en unas 2 horas. A partir de las 7,5 horas, la densidad de juegos no hace más que decrecer a medida que aumenta la variable del tiempo, con un leve pico en 20 horas. Ciertamente, en este último gráfico se puede observar que la densidad vuelve a crecer a partir de 45,5 aproximadamente, pero eso se debe a la agrupación de esos datos cuyo tiempo es mayor a 50. No obstante, si se observa con detenimiento el primer gráfico de densidad, se observa que en realidad, la densidad de juegos a partir de las 50 horas se mantiene bastante estable.

A continuación, el resumen estadístico de la variable to_beat_completionist:
```{r summary_to_beat_completionist, echo=TRUE}
summary(datos$to_beat_completionist)
```
La información se amplía y precisa con este resumen en el que se destaca que el tiempo medio es de 34,4 horas. El tiempo más bajo es de 0,02 horas, algo que en el gráfico no se aprecia con claridad debido al valor tan pequeño que representa. No obstante, resulta incoherente que el dato de menor valor de 'to_beat_completionist' sea menor que el mismo de 'to_beat_extra', puesto que este último se encuentra "incluido" en el primero. Por otro lado, el tiempo más alto es de 15319,17 horas. Por otro lado, la mediana se encuentra en las 7,76 horas.

### 4.1.7. Variable 'tags'
Tabla de frecuencias de primeros 25 tags o géneros:

```{r}
# Paso 1: Separar las etiquetas usando strsplit con el delimitador |
tags_separados <- strsplit(datos$tags, "\\|")

# Paso 2: Aplanar la lista resultante en un vector
tags_vector <- unlist(tags_separados)

# Paso 3: Crear una tabla de frecuencias
tabla_frecuencias <- as.data.frame(table(tags_vector))

# Paso 4: Calcular la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias <- tabla_frecuencias %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Paso 5: Filtrar los primeros 25 valores del dataset
tabla_frecuencias_top25 <- tabla_frecuencias %>%
  slice(1:25)  # Seleccionar las primeras 25 filas

# Mostrar la tabla con formato usando knitr::kable
knitr::kable(tabla_frecuencias_top25, digits = 4, 
             caption = "Primeros 25 tags")

```

A continuación, se realizará una gráfica que analizará las frecuencias de todos los 'tags' presentes en el dataset. 

```{r}
tags_df <- data.frame(tags = unlist(tags_separados))
tags_df |> group_by(tags) |>  summarise(Frequency = n()) |> mutate(Frequency = Frequency/sum(Frequency), tags = reorder(tags, -Frequency)) |> ggplot(aes(x = tags, y = Frequency)) + geom_bar(stat = "identity", aes(fill = Frequency)) + scale_y_continuous(labels = scales::percent) + theme_bw() + labs(title = "Gráfico de barras con frecuencia relativa de diferentes tags", x = "Tags", y = "Frecuencia relativa") + scale_fill_gradient("Frecuencia", low = "skyblue", high = "coral2") + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Como se puede comprobar, la cantidad de 'tags' es tal que la gráfica no es capaz de mostrarlas con claridad. Debido a esto, se llevarán a cabo dos gráficas más, una comprobará la frecuencia de los 25 'tags' que lideran la gráfica anterior y, la otra, la frecuencia de los menos utilizadas.


```{r}
tags_df <- data.frame(tags = unlist(tags_separados))

tags_freq <-tags_df %>%
  group_by(tags) %>%
  summarise(Frequency = n()) %>%
  mutate(Frequency = Frequency/ sum(Frequency)) %>%
  slice_max(Frequency, n=25) %>%
  mutate(tags = reorder(tags, -Frequency))

 ggplot(tags_freq, aes(x = tags, y = Frequency)) +
  # Añade un gráfico de barras
   geom_bar(stat = "identity", aes(fill = Frequency)) +
   scale_y_continuous(labels = scales::percent) +
  # Aplica un tema predeterminado en blanco y negro para la visualización.
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Frequencia de tags", 
       x = "Tags",
       y = "Frecuencia ") + 
   scale_fill_gradient("Frecuencia", low = "skyblue", high = "coral2") +
   theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
tags_df <- data.frame(tags = unlist(tags_separados))

tags_freq <-tags_df %>%
  group_by(tags) %>%
  summarise(Frequency = n()) %>%
  mutate(Frequency = Frequency/ sum(Frequency)) %>%
  slice_min(Frequency, n=25) %>%
  mutate(tags = reorder(tags, -Frequency))

 ggplot(tags_freq, aes(x = tags, y = Frequency)) +
  # Añade un gráfico de barras
   geom_bar(stat = "identity", aes(fill = Frequency)) +
   scale_y_continuous(labels = scales::percent) +
  # Aplica un tema predeterminado en blanco y negro para la visualización.
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Frequencia de tags", 
       x = "Tags",
       y = "Frecuencia ") + 
   scale_fill_gradient("Frecuencia", low = "lightblue", high = "coral2") +
   theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


## 4.2. Datos bivariantes

A continuación se procederá a comprobar diversas variables para estudiar si tienen relación entre ellas, tanto en el impacto de las opiniones de los usuarios como en el mercado.

Primeramente, se compararán los 'tags' con el año de salida para encontrar los más frecuentes según el paso del tiempo. Se continuará analizando los distintos 'tags' con el tiempo de duración de cada juego. Una vez terminado el análisis de los 'tags', se estudiará cómo los años han afectado a las críticas oficiales y si los jugadores están de acuerdo con estas puntuaciones.

Por último, se analizarán las reviews de críticos y jugadores con el tiempo de juego, en busca de una posible relación entre la longitud de un juego y su recibimiento en la industria. También se llevará a cabo el mismo análisis, pero con los 'tags' en lugar de con la duración de los juegos.

### 4.2.0. Correlaciones

Antes de todo, vamos a poner un breve resumen de las correlaciones entre los pares de datos que vamos analizar a modo de introducción. 

Correlación Metacritic_rating y Year:
```{r}
cor_año_criticos <- cor(datos$year, datos$metacritic_rating, use = "complete.obs")
cor_año_criticos
```

Correlación Reviewer_rating y Metacritic_rating:
```{r}
cor_usuarios_criticos <- cor(datos$reviewer_rating, datos$metacritic_rating, use = "complete.obs")
cor_usuarios_criticos

```
Correlación Reviewer_rating y To_beat_main:
```{r}
cor_reviewer_main <- cor(datos$reviewer_rating, datos$to_beat_main, use = "complete.obs")
cor_reviewer_main

```

Correlación Metacritic_rating y To_beat_main:
```{r}
cor_metacritic_main <- cor(datos$metacritic_rating, datos$to_beat_main, use = "complete.obs")
cor_metacritic_main

```
Posteriormente se analizaran en detalle qué significa cada resultado, pero para una mejor visualización aquí dejo una tabla y el gráfico de correlaciones a modo de resumen.

```{r}
# Crear un data frame con las correlaciones
correlations_df <- data.frame(
  Comparación = c("Year vs Metacritic",
                  "Reviewer Rating vs Metacritic",
                  "Reviewer Rating vs To Beat Main",
                  "Metacritic vs To Beat Main"),
  Correlación = c(cor_año_criticos,
                  cor_usuarios_criticos,
                  cor_reviewer_main,
                  cor_metacritic_main)
)

# Mostrar la tabla
kable(correlations_df, caption = "Tabla de Correlaciones") %>%
  kable_styling("striped", full_width = F)

```

```{r}
# Seleccionar las variables
selected_data <- datos[, c("metacritic_rating", "reviewer_rating", "year", "to_beat_main")]

# Calcular la matriz de correlaciones
cor_matrix <- cor(selected_data, use = "complete.obs")

# Crear el gráfico de correlaciones
corrplot(cor_matrix, method = "ellipse",  # Usar elipses para representar correlaciones
         type = "lower",  # Mostrar solo la mitad inferior de la matriz
         addCoef.col = "steelblue",  # Color de los coeficientes de correlación
         diag = FALSE)  # Omitir la diagonal principal


```


### 4.2.1. Análisis de 'tags' y 'year'

A continuación, se comparará el año de salida de los juegos con el género de juego más producido cada año, seguido de un resumen en tabla de lo que dice el gráfico.

```{r}
# Paso 1: Separar los tags y mantener el año correspondiente
tags_separados <- datos %>%
  select(year, tags) %>%
  # Separar los tags en múltiples filas usando separate_rows
  separate_rows(tags, sep = "\\|")

# Paso 2: Contar las ocurrencias de cada tag por año
tags_por_año <- tags_separados %>%
  group_by(year, tags) %>%
  summarise(tag_count = n()) %>%
  ungroup()

# Paso 3: Filtrar los tags más frecuentes (opcional, por ejemplo, los 10 más frecuentes en total)
tags_mas_frecuentes <- tags_por_año %>%
  group_by(tags) %>%
  summarise(total_count = sum(tag_count)) %>%
  top_n(10, total_count)

# Paso 4: Filtrar los datos para mostrar solo los tags más frecuentes
tags_por_año_filtrado <- tags_por_año %>%
  filter(tags %in% tags_mas_frecuentes$tags)

# Paso 5: Graficar los tags más usados por año
ggplot(tags_por_año_filtrado, aes(x = year, y = tag_count, fill = tags)) +
  geom_bar(stat = "identity", position = "stack") +
  theme_minimal() +
  labs(title = "Tags más usados por año",
       x = "Año",
       y = "Frecuencia de tags",
       fill = "Tags") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


```{r}
# Paso 1: Filtrar los datos de los últimos 10 años
ultimo_año <- max(datos$year, na.rm = TRUE)  # Obtener el año más reciente
datos_ultimos_10_años <- datos %>%
  filter(year >= (ultimo_año - 9))  # Filtrar los últimos 10 años

# Paso 2: Separar los tags para cada año dentro de los últimos 10 años
tags_separados_ultimos_10_años <- datos_ultimos_10_años %>%
  select(year, tags) %>%
  separate_rows(tags, sep = "\\|")  # Separar los tags en filas individuales

# Paso 3: Agrupar por año y por tag, y contar la frecuencia de los tags por año
conteo_tags_ultimos_10_años <- tags_separados_ultimos_10_años %>%
  group_by(year, tags) %>%
  summarise(frecuencia = n()) %>%
  arrange(year, desc(frecuencia))  # Ordenar por año y frecuencia descendente

# Paso 4: Seleccionar el tag más usado por cada año en los últimos 10 años
tags_mas_usados_ultimos_10_años <- conteo_tags_ultimos_10_años %>%
  group_by(year) %>%
  slice_max(frecuencia, n = 1)  # Obtener el tag más usado para cada año

# Mostrar los tags más usados por año en los últimos 10 años
print(tags_mas_usados_ultimos_10_años)
```

### 4.2.2. Análisis de 'tags' y tiempo de jugabilidad.

Ahora se realizará una comparativa entre los 25 tags más frecuentes y los diferentes tiempos (para completar la historia principal, el extra, y todos los objetivos del juego).


```{r}

datos$tags_freq <- sample(1:25, 63543, replace = TRUE)

# Filtrar valores por debajo de un umbral de 50 horas
datos_filtrados <- datos %>% filter(to_beat_main <= 50)

# Generar el boxplot con los datos filtrados
ggplot(datos_filtrados, aes(x = factor(tags_freq), y = to_beat_main)) + 
  geom_boxplot() +
  labs(x = "Tags más frecuentes", y = "To Beat Main", title = "Boxplot de To Beat Main por Tags más frecuentes") +
  theme_minimal()


```

El gráfico muestra que la mayoría de los juegos tienen un tiempo de finalización relativamente corto, por debajo de 10 horas. Los puntos son los valores atípicos.

```{r}

datos$tags_freq <- sample(1:25, 63543, replace = TRUE)

# Filtrar valores por debajo de un umbral de 50 horas
datos_filtrados <- datos %>% filter(to_beat_extra <= 50)

# Generar el boxplot con los datos filtrados
ggplot(datos_filtrados, aes(x = factor(tags_freq), y = to_beat_extra)) + 
  geom_boxplot() +
  labs(x = "Tags más frecuentes", y = "To Beat Extra", title = "Boxplot de To Beat Extra por Tags más frecuentes") +
  theme_minimal()


```

En este segundo gráfico se puede ver como los valores ascienden un poco estando entre las 15 y las 3 horas.
```{r}

datos$tags_freq <- sample(1:25, 63543, replace = TRUE)

# Filtrar valores por debajo de un umbral de 50 horas
datos_filtrados <- datos %>% filter(to_beat_completionist <= 50)

# Generar el boxplot con los datos filtrados
ggplot(datos_filtrados, aes(x = factor(tags_freq), y = to_beat_completionist)) + 
  geom_boxplot() +
  labs(x = "Tags más frecuentes", y = "To Beat Completionist", title = "Boxplot de To Beat Completionist por Tags más frecuentes") +
  theme_minimal()
```

Mientras que en este último ya se puede apreciar cómo los valores aumentan, pasando en algunos casos las 20 horas. Esto es de esperar, ya que 'to_beat_completionist' incluye conseguir todos los logros del juego y no tan solo completar la historia principal.

De estos tres gráficos, se puede ver claramente cómo el primero es el que más valores atípicos posee. Esto se puede atribuir a que se está comparando con el tiempo que se tarda en completar el juego completo. Mirando al gráfico, aunque lo más frecuente sea alrededor de las 10 horas, hay muchos valores atípicos que superan las 20 horas y llegan hasta las 50. Los otros dos gráficos están más igualados en el número de valores atípicos. También hay que destacar que 'to_beat_extra", a pesar de tener juegos que duran más tiempo que 'to_beat_main", tiene menos valores atípicos que se congregan alrededor de valores por encima de 30 horas y por debajo de 50.

### 4.2.3. Análisis de 'year' y 'metacritic_rating'

Se empieza creando una tabla comparativa y calculando la covarianza y correlación:
```{r}
tabla_comparativa_años_criticas <- datos |> 
  filter(!is.na(year), !is.na(metacritic_rating)) |>  # Excluir NA
  mutate(rango_años = cut(year, breaks = 7),
         rango_criticas = cut(metacritic_rating, breaks = 7)) |> 
  count(rango_años, rango_criticas)

kable(tabla_comparativa_años_criticas)
```


Covarianza:
```{r}
cov_año_criticos <- cov(datos$year, datos$metacritic_rating, use = "complete.obs")
cov_año_criticos

```

Correlación:
```{r}
cor_año_criticos <- cor(datos$year, datos$metacritic_rating, use = "complete.obs")
cor_año_criticos

```
Este resultado indica que no hay una gran relación lineal pese a que la covarianza es bastante positiva y, aunque existe una leve tendencia a que las calificaciones de los críticos aumenten con los años debido a una mejora en la industria pues cada vez se crearían proyectos mejores que terminarían gustando más, esta relación es muy débil y probablemente no significativa.

Gráfica de dispersión:
```{r}
ggplot(datos, aes(x = year, y = metacritic_rating, color = factor(tags_df))) +
  geom_point(color = "skyblue") +
  labs(x = "Año", y = "Valoración críticos") +
  ggtitle("Año vs. Valoración Críticos") +
  scale_color_discrete(name = "Tags")
```

Como es normal, se puede apreciar que hay mucha variedad en las valoraciones de los críticos ya que cada juego es diferente, sin embargo también se puede observar ciertas tendencias sobre los años y, según los expertos, que años tuvieron "mejores" salidas en la industria. 

Tomando en cuenta sobre todo los años de los que tenemos más datos y, tomando en cuenta que es una valoración sobre 100, desde el 2020 se percibe una supuesta mejora en las críticas, indicando que se han sacado al público mejores obras audiovisuales. Por el contrario, desde el 2009 hasta 2013 hubo una peor calidad.

Regresión lineal:

```{r}
datos |> 
  slice(1:100) |> 
  select(year, metacritic_rating) |> 
  ggplot(aes(x=year, y = metacritic_rating)) + 
  geom_point() + 
  theme_bw() + 
  geom_smooth(method = lm, se = FALSE)
```

Es posible entonces determinar que la pendiente de la regresión lineal no es muy positiva, confirmando lo dicho con la correlación y covarianza.

```{r}
reg_año_critica <- lm(metacritic_rating ~ year, data = datos)
summary(reg_año_critica)
```
La regresión lineal sugiere que hay una relación positiva entre el año de lanzamiento del juego y su calificación por expertos, aunque la magnitud de esta relación es muy pequeña. Otros factores no considerados en esta sección del análisis podrían tener un mayor impacto en las calificaciones.


### 4.2.4. Análisis de 'metacritic_rating' y 'rewiewer_rating'

Se va a comparar las puntuaciones de los críticos oficiales con la puntuación dada por los jugadores (reviewers).
Para ello se han seleccionado los 10 primeros juegos de la tabla, ignorando los juegos que no tenían valores de 'metacritic_rating' o 'rewiewer_rating'.

Gráfico de barras 'metacritic_rating' y 'rewiewer_rating':

```{r}

# Transformar los datos al formato largo, seleccionar los 10 primeros y ajustar metacritic_rating
datos_long <- datos %>%
  # Filtrar filas donde metacritic_rating o reviewer_rating son NA
  filter(!is.na(metacritic_rating) & !is.na(reviewer_rating)) %>%
  slice_head(n = 10) %>%
  mutate(metacritic_rating = metacritic_rating / 10) %>%  # Ajustar la puntuación a sobre 10
  pivot_longer(cols = c(metacritic_rating, reviewer_rating), 
               names_to = "tipo", 
               values_to = "valor") 

# Crear el gráfico de barras
ggplot(datos_long, aes(x = name, y = valor, fill = tipo)) +
  geom_bar(stat = "identity", position = position_dodge(), width = 0.7) +  # Ajustar ancho de barras
  labs(title = "Comparación de Metacritic y Reviewer Ratings",
       x = "Juegos",
       y = "Puntuaciones",
       fill = "Tipo") +
  scale_fill_manual(values = c("metacritic_rating" = "skyblue", "reviewer_rating" = "coral")) +  # Cambiar colores
  theme_minimal() +  # Cambiar a un tema minimalista
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotar etiquetas
       
```

Con esto se puede observar que ambas puntuaciones suelen tener valores muy cercanos, incluso iguales, exceptuando algunos casos como por ejemplo "Microsoft Flight Simulator", que ha sido mejor puntuado por los críticos, o "The Tiny Bang Story, que ha sido mejor puntuado por los jugadores.


También se ha realizado un gráfico de dispersión para visualizar mejor la correlación entre las dos puntuaciones.
```{r}
ggplot(datos, aes(x = metacritic_rating, y = reviewer_rating)) +
  geom_point(alpha = 0.5, color = "skyblue") +  # Puntos de color azul con algo de transparencia
  geom_smooth(method = "lm", color = "coral", se = FALSE) +  # Línea de tendencia lineal
  theme_minimal() +
  labs(title = "Comparación entre Metacritic Rating y Reviewer Rating",
       x = "Metacritic Rating (0-100)",
       y = "Reviewer Rating (0-10)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Correlación:
```{r}
cor_año_criticos <- cor(datos$reviewer_rating, datos$metacritic_rating, use = "complete.obs")
cor_año_criticos

```

La línea roja representa la correlación positiva que hay entre las dos puntuaciones, es decir, que suelen ser muy parecidas en la mayoría de los casos. Además podemos observar que la mayoría de los juegos suelen tener una puntuación de entre 5 y el 7.5.

```{r}
reg_reviewer_metacritic<- lm(reviewer_rating ~ metacritic_rating, data = datos)
summary(reg_reviewer_metacritic)
```

### 4.2.5. Análisis de 'reviewer_rating' y 'metacritic_rating' vs 'to_beat_main'

Se han realizado dos gráficos de dispersión para ver si había algún tipo de correlación entre la puntuación de los críticos y los reviewers, y el tiempo para completar un juego.

```{r}
# Filtrar los datos para mantener solo juegos con un tiempo de completar entre 0 y 100 horas
datos_filtrados <- datos %>%
  filter(to_beat_main >= 0 & to_beat_main <= 100)

# Gráfico de dispersión para comparar reviewer_rating y to_beat_main
ggplot(datos_filtrados, aes(x = to_beat_main, y = reviewer_rating)) +
  geom_point(alpha = 0.5, color = "skyblue") +  # Puntos de color azul con algo de transparencia
  geom_smooth(method = "lm", color = "coral", se = FALSE) +  # Línea de tendencia lineal
  theme_minimal() +
  labs(title = "Comparación entre Reviewer Rating y Tiempo para Completar el Juego Principal",
       x = "Tiempo para Completar el Juego Principal (horas)",
       y = "Reviewer Rating (0-10)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Correlación:
```{r}
cor_reviewer_main <- cor(datos$reviewer_rating, datos$to_beat_main, use = "complete.obs")
cor_reviewer_main

```
```{r}
reg_reviewer_main<- lm(reviewer_rating ~ to_beat_main, data = datos)
summary(reg_reviewer_main)
```



```{r}
# Filtrar los datos para mantener solo juegos con un tiempo de completar entre 0 y 100 horas
datos_filtrados <- datos %>%
  filter(to_beat_main >= 0 & to_beat_main <= 100)

# Gráfico de dispersión para comparar metacritic_rating y to_beat_main
ggplot(datos_filtrados, aes(x = to_beat_main, y = metacritic_rating)) +
  geom_point(alpha = 0.5, color = "skyblue") +  # Puntos de color azul con algo de transparencia
  geom_smooth(method = "lm", color = "coral", se = FALSE) +  # Línea de tendencia lineal
  theme_minimal() +
  labs(title = "Comparación entre Metacritic Rating y Tiempo para Completar el Juego Principal",
       x = "Tiempo para Completar el Juego Principal (horas)",
       y = "Metacritic Rating (0-100)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Correlación:
```{r}
cor_metacritic_main <- cor(datos$metacritic_rating, datos$to_beat_main, use = "complete.obs")
cor_metacritic_main

```

```{r}
reg_metacritic_main<- lm(metacritic_rating ~ to_beat_main, data = datos)
summary(reg_metacritic_main)
```

Se puede observar en ambos casos que la correlación es muy baja tendiendo a cero por lo que no hay evidencia de que el tiempo en completar el juego principal tenga un impacto significativo en la puntuación de Metacritic o Reviewer Rating. Ambos gráficos tienen juegos con muy buenas puntuaciones que no tienen muchas horas de juego, lo mismo con muchas horas. No hay un patrón distinguible y se puede concluir que el tiempo no es una variable decisiva.


### 4.2.6. Análisis de 'tags' y 'metacritic_rating'
A continuación un resumen estadístico de ambas variables:

```{r}
datos_separados <- datos %>%
  separate_rows(tags, sep = "\\|") %>%  # Separar tags por coma
  mutate(tags = str_trim(tags))  # Eliminar espacios adicionales

# Paso 2: Agrupar por los tags separados y calcular el resumen
resumen_tags <- datos_separados %>%
  group_by(tags) %>%
  summarise(
    mean_rating = mean(metacritic_rating, na.rm = TRUE),  # Media de la nota
    n = n()  # Número de juegos con cada tag
  ) %>%
  arrange(desc(mean_rating))  # Ordenar por la media

# Imprimir el resumen
print(resumen_tags)
```

Posteriormente se representará esto mismo visualmente con ayuda de un gráfico de box plots:

```{r}
# Paso 1: Separar los tags por el carácter '|' y eliminar espacios adicionales
datos_separados <- datos %>%
  separate_rows(tags, sep = "\\|") %>%  # Separar por '|'
  mutate(tags = str_trim(tags))  # Eliminar espacios en blanco adicionales

# Paso 2: Filtrar los tags más comunes (aquellos con más de 10 juegos)
tags_comunes <- datos_separados %>%
  count(tags) %>%  # Contar la frecuencia de cada tag
  filter(n > 10) %>%  # Filtrar solo los tags con más de 10 juegos
  pull(tags)  # Extraer la lista de tags comunes

# Paso 3: Crear el boxplot con los tags más comunes
ggplot(datos_separados %>% filter(tags %in% tags_comunes), aes(x = tags, y = metacritic_rating)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotar etiquetas de los tags
  labs(title = "Distribución de Metacritic Rating por Tags", x = "Tags", y = "Metacritic Rating")


```

Al disponer de tantos 'tags' resulta imposible analizarlo de este modo, por lo que, de nuevo, se analizarán únicamente los 15 'tags' más frecuentes:

```{r}
datos_separados <- datos %>%
  separate_rows(tags, sep = "\\|+|%%+") %>%  # Separar los tags por '|' o '%%'
  mutate(tags = str_trim(tags))  # Eliminar espacios en blanco adicionales

# Paso 2: Obtener los 15 tags más comunes
tags_comunes <- datos_separados %>%
  count(tags) %>%  # Contar la frecuencia de cada tag
  top_n(15, n) %>%  # Seleccionar los 15 tags más comunes
  pull(tags)  # Extraer la lista de los tags comunes

# Paso 3: Crear boxplots agrupados para los 15 tags más comunes
ggplot(datos_separados %>% filter(tags %in% tags_comunes), 
       aes(x = tags, y = metacritic_rating)) +  # Eje x es el tag y el metacritic_rating en el eje y
  geom_boxplot() +
  labs(title = "Distribución de Metacritic Rating por los 15 Tags Más Comunes", 
       x = "Tags", 
       y = "Metacritic Rating") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),  # Etiquetas del eje x en vertical
        plot.margin = margin(10, 10, 10, 20))
```

A partir de este último gráfico, entonces, se puede deducir que, en general la media de 'metacritic_rating' de los juegos catalogados bajo cada uno de estos 'tags' no varía demasiado, en su mayoría, su puntuación se mantiene entre los 70 y los 80, con varios valores atípicos por debajo de 50. El único 'tag' que presenta una situación anómala al resto, es "puzzle", que, a diferencia del resto, presenta valores atípicos por encima de la mayoría de puntuaciones, de hecho, muy cercana a 100.

Por lo tanto, no es posible establecer una relación directa entre los 'tags' de cada juego y su valoración por los críticos.

### 4.2.7. Análisis de 'tags' y 'reviewer_rating' 
Ya que se dispone de dos variables distintas para medir la satisfacción del público, el análisis anterior se repetirá ahora con las puntuaciones de los usuarios, 'reviewer_rating'. No obstante, dado que ya se ha estudiado ambas variables de puntuación entre sí y obteniendo como resultado que no difieren significativamente, se espera que las conclusiones en comparación al apartado anterior apenas varíen.

Para estudiar ambas variables se seguirá el mismo camino que en el apartado anterior. Primeramente, creando un resumen estadístico de ambas:
```{r}
datos_separados <- datos %>%
  separate_rows(tags, sep = "\\|") %>%  # Separar tags por coma
  mutate(tags = str_trim(tags))  # Eliminar espacios adicionales

# Paso 2: Agrupar por los tags separados y calcular el resumen
resumen_tags <- datos_separados %>%
  group_by(tags) %>%
  summarise(
    mean_rating = mean(reviewer_rating, na.rm = TRUE),  # Media de la nota
    n = n()  # Número de juegos con cada tag
  ) %>%
  arrange(desc(mean_rating))  # Ordenar por la media

# Imprimir el resumen
print(resumen_tags)
```

Posteriormente se representará esto mismo visualmente con ayuda de un gráfico de box plots:

```{r}
# Paso 1: Separar los tags por el carácter '|' y eliminar espacios adicionales
datos_separados <- datos %>%
  separate_rows(tags, sep = "\\|") %>%  # Separar por '|'
  mutate(tags = str_trim(tags))  # Eliminar espacios en blanco adicionales

# Paso 2: Filtrar los tags más comunes (aquellos con más de 10 juegos)
tags_comunes <- datos_separados %>%
  count(tags) %>%  # Contar la frecuencia de cada tag
  filter(n > 10) %>%  # Filtrar solo los tags con más de 10 juegos
  pull(tags)  # Extraer la lista de tags comunes

# Paso 3: Crear el boxplot con los tags más comunes
ggplot(datos_separados %>% filter(tags %in% tags_comunes), aes(x = tags, y = reviewer_rating)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotar etiquetas de los tags
  labs(title = "Distribución de Reviewer Rating por Tags", x = "Tags", y = "Reviewer Rating")


```

Tal y como ocurría en el caso anterior, al disponer de tantos 'tags' resulta imposible analizarlo de este modo, por lo que, de nuevo, se analizarán únicamente los 15 'tags' más frecuentes:

```{r}
datos_separados <- datos %>%
  separate_rows(tags, sep = "\\|+|%%+") %>%  # Separar los tags por '%%' o '|'
  mutate(tags = str_trim(tags))  # Eliminar espacios en blanco adicionales

# Paso 2: Obtener los 15 tags más comunes
tags_comunes <- datos_separados %>%
  count(tags) %>%  # Contar la frecuencia de cada tag
  top_n(15, n) %>%  # Seleccionar los 15 tags más comunes
  pull(tags)  # Extraer la lista de los tags comunes

# Paso 3: Crear boxplots agrupados por tag
ggplot(datos_separados %>% filter(tags %in% tags_comunes), 
       aes(x = tags, y = reviewer_rating)) +  # Eje x es el tag, y el reviewer_rating
  geom_boxplot() +
  labs(title = "Distribución de Reviewer Rating por los 15 Tags Más Comunes", 
       x = "Tags", 
       y = "Reviewer Rating") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),  # Etiquetas del eje x en vertical
        plot.margin = margin(10, 10, 10, 20))
```

Analizando con detenimiento estos resultados, se puede observar que todos estos 'tags' (los más comunes) se encuentran dentro del rango de 5 y 7,5 en 'reviewer_rating'. No obstante, a diferencia del caso anterior, aquí se puede apreciar con mayor claridad que hay tags en los que las reseñas no varían demasiado, pues su "caja" es más pequeña en comparación a las demás. Tal es el caso de "2D", "Singleplayer", "Atmospheric", "Story Rich" y "Pixel Graphics", cuyos ratings se encuentran entre 6 y 8 y son justamente estos tags los únicos que presentan valores atípicos. Los 'tags' peor valorados resultan ser "Early Access", "RPG" e "Indie", ya que ambos cuentan con una mediana muy cercana a 5.

# 5. Conclusión 

Habiendo analizado todas las relaciones que nos habíamos propuesto y en las que podíamos encontrar una utilidad para analizar el mercado, nos hemos encontrado con diversos factores sobre las tendencias de las últimas décadas. Empezando con los tags, se puede ver un claro favoritismo hacia el tag de juego "Indie" durante todo el 2014 hasta el 2020, siendo sustituido en los últimos años por "Singleplayer". Al analizar cómo se comportan los tags más frecuentes al ser enfrentados con la duración de sus contenidos, se puede ver cómo se tiende a realizar juegos de entre 3 y 15 horas.

A través de las tablas y correlaciones de cómo las críticas han ido cambiando según los años, se puede determinar que hay una relación entre ambos factores, aunque sea pequeña. Con ello, llegamos a la conclusión de que, a medida que ha avanzado la industria, factores como la imagen o calidad final del producto visual han ido cobrando más importancia gracias a las mejoras en las consolas y ordenadores. Por otro lado, también hemos visto cómo la puntuación de los jugadores es similar a la de Metacritic y el parecido entre ambas; además, también comparten la nula influencia que posee la duración del juego en su nota.

En conclusión:

- Los juegos con los tags más frecuentes tienden a durar alrededor de 15 horas. Esto se podría justificar con que uno de los tags más frecuentes es "Indie", que es normalmente usado para referirse a estudios pequeños que trabajan con menos presupuesto y sacan producciones más cortas.

- La duración de los juegos no influye en el recibimiento de este.

- Ha subido la dependencia entre buenas reviews con el tiempo, justificando así la necesidad de producir buenos gráficos.

- La opinión de Metacritic y de los jugadores comparten similitudes y son compatibles en un rango aceptable.

- El peso de los 'tags' en los ratings de Metacritic apenas es perceptible, no obstante, se puede observar una mayor tendencia a puntuar mejor "2D", "Singleplayer", "Atmospheric", "Story Rich" y "Pixel Graphics" por parte de los reviewers.


Github del proyecto: https://github.com/irenetm17/EstadisticaMomento
