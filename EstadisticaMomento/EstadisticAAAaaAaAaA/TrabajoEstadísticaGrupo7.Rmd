---
title: "EDA: Steam"
author: "Grupo7"
date: "2024-09-24"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,          
  message = FALSE,      # Oculta mensajes (como los de carga de paquetes)
  warning = FALSE       # Oculta advertencias (warnings)
)

```


# Introducción y definición de objetivos

Mediante el estudio estadístico de datos obtenidos sobre los juegos publicados en la plataforma de Steam desde 2005, se pretende conocer y analizar si es posible establecer alguna relación entre las diversas variables que se toman en cuenta en dicho estudio (año de lanzamiento, puntuación media de usarios, etc.).

Al disponer de variables enlazadas directamente a la acogida por parte del público de los diversos títulos de Steam, el principal próposito de esta investigación es llevar a cabo un estudio de mercado sobre los mismos. De este modo se analizaría si es posible establecer una conexión directa entre la satisfacción del púbico y otras variables como podrían ser la duración o los tags. Esta última podría resultar sumamente interesante puesto que sería posible explorar las tendencias de los usuarios a la hora de puntuar juegos de determinados géneros o categorías, profundizando así más allá de los aspectos técnicos del videojuego (como el tiempo de contenido), en lo que el usuario busca experimentar sensorial, emocional o psicológicamente a la hora de decidir qué jugar. Asimismo, dado que las valoraciones profesionales no tienen por qué coincidir con las de los usuarios, también sería de interés estudiar cómo difieren entre sí.

Por otro lado, también se pretende llevar a cabo un análisis sobre los propios desarrolladores, descubriendo así cuáles son los géneros que tienen más lanzamientos cada año y si es posible establecer una relación con las valoraciones de lanzamientos del mismo género de años anteriores.


# Importación de datos y carga de paquetes


```{r}
library(tidyverse)
library(summarytools)
library(GGally)
library(gt)
library(flextable)
library(knitr)
library(corrplot)
library(kableExtra)
library(ggplot2)
library(tidyr)
library(dplyr)
library(psych)

```


```{r}
#Lee el dataset al que hemos llamado datos
datos <- readxl::read_excel("dataset.xlsx") 

```
              
# Diccionario de datos

* `id`: Identificador del juego (identificador)
* `name`: Nombre del juego (identificador)
* `year`: Año de salida al mercado (numérica discreta)
* `metacritic_rating`: Nota media de valoración profesional (numérica discreta, valor sobre 100)
* `reviewer_rating`: Nota media de la valoración de los usuarios   (numérica discreta, sobre 10)
* `positivity_ratio`: Ratio de positividad, cociente entrev las Valoraciones positivas y las valoraciones negativas (numérica continua)
* `to_beat_main`: Tiempo medio necesario para superar el juego principal (numérica continua, medida en horas)
* `to_beat_extra`: Tiempo medio necesario para superar el juego principal y contenido extra (numérica continua, medida en horas)
* `to_beat_completionist`: Tiempo medio para completar todo el contenido del juego y obtener todo sus logros (numérica continua, medida en horas)
* `extra_content_length`: Diferencia de tiempo entre el contenido principal y el extra (numérica continua, medida en horas)
* `tags`: Categorías o "tags" bajo las que se encuentra inscrito cada juego (categórica multinivel)

# Análisis exploratorio de datos

El estudio de este dataset constará de dos partes, por un lado, se llevará a cabo un análisis univariante de todas y cada una de las variables y, por otro lado, un análisis bivariante entre algunas de las variables.


## Datos univariantes

### Variable 'year'
```{r}
# Crea una tabla de frecuencias
tabla_frecuencias2 <- as.data.frame(table(datos$year))

# Calcula la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

#Muestra la tabla con formato
knitr::kable(tabla_frecuencias2, digits = 4)
```


```{r}
datos |> 
  # Inicia la visualización 
  ggplot(aes(x = year)) +
  # Añade un gráfico de barras, rellenando las barras
  geom_bar(fill = "skyblue") +
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Juegos por año", 
       x = "Año de salida (2005-2023)",
       y = "Cantidad de juegos")
      
```

```{r}
datos |> descr(year)
```

Podemos observar como la producción de los videojuegos lleva en auge las últimas décadas, haciendo un salto en 2015, además de cómo se frenó la caída de la industria en el año 2020 debido a la pandemia mundial y a la cuarentena. 

### Variable 'metacritic_rating'
```{r}
#Crea una tabla de frecuencias
tabla_frecuencias2 <- as.data.frame(table(datos$metacritic_rating))

#Calcula la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

#Muestra la tabla con formato
knitr::kable(tabla_frecuencias2, digits = 4)
```
```{r}
datos |> 
  # Inicia una visualización
  ggplot(aes(x = metacritic_rating)) +
  # Añade un gráfico de barras, rellenando las barras 
  geom_bar(fill = "skyblue") +
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Puntuación del crítico", 
       x = "Puntuación (0-100)",
       y = "Frecuencia absoluta") +
   scale_x_continuous(breaks = seq(20, 100, by = 10))  # Define más marcas en el eje X cada 10 unidades
      
```

En este gráfico se observa que las puntuaciones más frecuentes se encuentran entre los 60 y 85 puntos. La puntuación más frecuente, es decir, la moda, son 80 puntos, llegando a una frecuencia de casi 200.

```{r}
summary(datos$metacritic_rating)

```

La información se amplía con este resumen en el que destacamos que la puntuación media son 72,84 puntos. La nota más baja son 20 puntos y la más alta 97 puntos. Se concluye que no hay ningún juego que tenga una puntuación de 100.



### Variable 'reviewer_rating'
```{r}
# Crea una tabla de frecuencias
tabla_frecuencias2 <- as.data.frame(table(datos$reviewer_rating))

# Calcula la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

#Muestra la tabla con formato
knitr::kable(tabla_frecuencias2, digits = 4)
```

```{r}
datos |> 
  # Inicia una visualización 
  ggplot(aes(x = reviewer_rating)) +
  # Añade un gráfico de barras, rellenando las barras 
   geom_bar(fill = "skyblue") +
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Puntuación del jugador", 
       x = "Puntuación (0-10)",
       y = "Frecuencia absoluta") +
  scale_x_continuous(breaks = seq(0, 10, by = 1))  # Define más marcas en el eje X cada unidad
```

En este gráfico se observa que las puntuaciones más frecuentes se encuentran entre los 5 y 8 puntos. La puntuación más frecuente, es decir, la moda, son 8 puntos, seguido muy de cerca por los 5 puntos. 

```{r}
summary(datos$reviewer_rating)
```

La información se amplía con este resumen en el que destacamos que la puntuación media son 6,14 puntos. La nota más baja es 1 punto, algo que en el gráfico no se aprecia con claridad. La más alta son 9 puntos. Al igual que en las metacritic ratings, no hay ningún juego con una puntuación de 10.

### Variable 'positivity_ratio'
```{r}
# Crear la tabla de frecuencias a partir de datos$positivity_ratio
tabla_frecuencias2 <- as.data.frame(table(datos$positivity_ratio))

# Calcular la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),  # Frecuencia relativa
         N = cumsum(Freq),      # Frecuencia acumulada
         F = cumsum(f))         # Frecuencia relativa acumulada

# Filtrar los 10 menos frecuentes y los 10 más frecuentes
tabla_top_bottom <- tabla_frecuencias2 %>%
  arrange(Freq) %>%                       # Ordenar por frecuencia
  slice(c(1:10, (n() - 9):n()))           # Seleccionar las 10 primeras y 10 últimas filas

# Mostrar la tabla formateada con knitr
knitr::kable(tabla_top_bottom, digits = 4, 
             caption = "Tabla de Frecuencias: 10 Menos y Más Frecuentes")

```

### Variable 'to_beat_main'
```{r}
# Crear una tabla de frecuencias a partir de la variable 'to_beat_main'
tabla_frecuencias2 <- as.data.frame(table(datos$to_beat_main))

# Calcular la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)

tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Filtrar solo los primeros 25 valores de la tabla
tabla_frecuencias2_top25 <- tabla_frecuencias2 %>%
  slice(1:25)  # Seleccionar las primeras 25 filas

# Mostrar la tabla con formato usando knitr::kable
knitr::kable(tabla_frecuencias2_top25, digits = 4, 
             caption = "Primeros 25 Valores de 'to_beat_main'")

```

### Variable 'to_beat_extra'
```{r}
# Crea una tabla de frecuencias a partir de la variable 'to_beat_extra'
tabla_frecuencias2 <- as.data.frame(table(datos$to_beat_extra))

# Calcula la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)

tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Filtrar los primeros 25 valores del dataset
tabla_frecuencias2_top25 <- tabla_frecuencias2 %>%
  slice(1:25)  # Seleccionar las primeras 25 filas

# Mostrar la tabla con formato usando knitr::kable
knitr::kable(tabla_frecuencias2_top25, digits = 4, 
             caption = "Primeros 25 Valores de 'to_beat_extra'")

```

A continuación el gráfico de densidad de 'to_beat_main' sin agrupar datos:
```{r density_plot, echo=TRUE}
# Filtrar los datos para eliminar valores NA
datos_filtrados <- datos %>%
  filter(!is.na(to_beat_extra))

# Crear el gráfico de densidad
ggplot(datos_filtrados, aes(x = to_beat_main)) +
  geom_density(fill = "skyblue", color = "coral1", alpha = 0.6) +
  labs(title = "Distribución del Tiempo para Completar el Juego Principal y su Contenido Extra",
       x = "Tiempo para Completar el Juego Principal y su Contenido Extra (horas)",
       y = "Densidad") +
  theme_minimal()
```

Dado que la existencia de muy pocos datos con valores muy grandes dificulta el análisis del gráfico de densidad, se ha optado por hacer otro gráfico de densidad agrupando los datos más grandes, a partir de 50 horas, en un mismo valor. De este modo, es posible analizar con mayor precisión los datos en este rango de 0 a 50 horas, que es donde se encuentran la mayoría de ellos. Al aplicar este cambio, se obtiene el siguiente gráfico de densidad:

```{r density_plot_grouped_extra, echo=TRUE}
# Filtrar los datos para eliminar valores NA
datos_filtrados_extra <- datos %>%
  filter(!is.na(to_beat_extra))

# Agrupar valores mayores a 50 horas en una nueva categoría
datos_filtrados_extra <- datos_filtrados_extra %>%
  mutate(to_beat_extra_grouped = ifelse(to_beat_extra > 50, 50, to_beat_extra))

# Crear el gráfico de densidad usando la variable agrupada
ggplot(datos_filtrados_extra, aes(x = to_beat_extra_grouped)) +
  geom_density(fill = "skyblue", color = "coral1", alpha = 0.6) +
  labs(title = "Distribución del Tiempo para Completar el Juego Principal y Contenido Extra (Agrupando > 50h)",
       x = "Tiempo para Completar el Juego Principal y Contenido Extra (horas)",
       y = "Densidad") +
  theme_minimal() +
  scale_x_continuous(breaks = c(seq(0, 50, by = 10)), labels = c(seq(0, 40, by = 10), "50+"))

```

A partir de estos dos gráficos, entonces, es posible establecer una clara predominancia de juegos cuyo contenido principal y extras tan solo requieren entre 0 y 10 horas para completarse, con un pico claro en unas 3 horas. A partir de las 10 horas, la densidad de juegos no hace más que decrecer a medida que aumenta la variable del tiempo, con un leve pico en 20 horas. Ciertamente, en este último gráfico se puede observar que la densidad vuelve a crecer a partir de 47 aproximadamente, pero eso se debe a la agrupación de esos datos cuyo tiempo es mayor a 50. No obstante, si se observa con detenimiento el primer gráfico de densidad, se observa que en realidad, la densidad de juegos a partir de las 50 horas se mantiene bastante estable.

Resumen estadístico de to_beat_main
A continuación, el resumen estadístico de la variable to_beat_extra:
```{r summary_to_beat_extra, echo=TRUE}
# Resumen básico utilizando summary()
resumen_basico <- summary(datos$to_beat_extra)
print(resumen_basico)

# Resumen más detallado utilizando psych
library(psych)
resumen_detallado <- describe(datos$to_beat_extra)
print(resumen_detallado)

# Resumen utilizando dplyr para obtener media, mediana, desviación estándar, mínimo y máximo
resumen_tidy <- datos %>%
  summarise(
    media = mean(to_beat_extra, na.rm = TRUE),
    mediana = median(to_beat_extra, na.rm = TRUE),
    desviacion_estandar = sd(to_beat_extra, na.rm = TRUE),
    minimo = min(to_beat_extra, na.rm = TRUE),
    maximo = max(to_beat_extra, na.rm = TRUE)
  )

print(resumen_tidy)

```

### Variable 'to_beat_completionist'
```{r}
# Crea una tabla de frecuencias
tabla_frecuencias2 <- as.data.frame(table(datos$to_beat_completionist))

# Calcula la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias2 <- tabla_frecuencias2 %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Filtrar los primeros 25 valores del dataset
tabla_frecuencias2_top25 <- tabla_frecuencias2 %>%
  slice(1:25)  # Seleccionar las primeras 25 filas

# Mostrar la tabla con formato usando knitr::kable
knitr::kable(tabla_frecuencias2_top25, digits = 4, 
             caption = "Primeros 25 Valores de 'to_beat_completionist'")
```

### Variable 'extra_content_length'
Esta variable no se va analizar debido a su poca relación con el resto del EDA.

### Variable 'tags'

```{r}
# Paso 1: Separar las etiquetas usando strsplit con el delimitador |
tags_separados <- strsplit(datos$tags, "\\|")

# Paso 2: Aplanar la lista resultante en un vector
tags_vector <- unlist(tags_separados)

# Paso 3: Crear una tabla de frecuencias
tabla_frecuencias <- as.data.frame(table(tags_vector))

# Paso 4: Calcular la frecuencia relativa (f), frecuencia acumulada (N) y frecuencia relativa acumulada (F)
tabla_frecuencias <- tabla_frecuencias %>%
  mutate(f = Freq / sum(Freq),         # Frecuencia relativa
         N = cumsum(Freq),             # Frecuencia acumulada
         F = cumsum(f))                # Frecuencia relativa acumulada

# Paso 5: Filtrar los primeros 25 valores del dataset
tabla_frecuencias_top25 <- tabla_frecuencias %>%
  slice(1:25)  # Seleccionar las primeras 25 filas

# Mostrar la tabla con formato usando knitr::kable
knitr::kable(tabla_frecuencias_top25, digits = 4, 
             caption = "Primeros 25 tags")

```

A continuación, se realizará una gráfica que analizará las frecuencias de todos los 'tags' presentes en el dataset. 

```{r}
tags_df <- data.frame(tags = unlist(tags_separados))
tags_df |> group_by(tags) |>  summarise(Frequency = n()) |> mutate(Frequency = Frequency/sum(Frequency), tags = reorder(tags, -Frequency)) |> ggplot(aes(x = tags, y = Frequency)) + geom_bar(stat = "identity", aes(fill = Frequency)) + scale_y_continuous(labels = scales::percent) + theme_bw() + labs(title = "Gráfico de barras con frecuencia relativa de diferentes tags", x = "Tags", y = "Frecuencia relativa") + scale_fill_gradient("Frecuencia", low = "skyblue", high = "coral2") + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Como se puede comprobar, la cantidad de 'tags' es tal que la gráfica no es capaz de mostrarlas con claridad. Debido a esto, se llevarán a cabo dos gráficas más, una comprobará la frecuencia de los 25 'tags' que lideran la gráfica anterior y, la otra, la frecuencia de los menos utilizadas.


```{r}
tags_df <- data.frame(tags = unlist(tags_separados))

tags_freq <-tags_df %>%
  group_by(tags) %>%
  summarise(Frequency = n()) %>%
  mutate(Frequency = Frequency/ sum(Frequency)) %>%
  slice_max(Frequency, n=25) %>%
  mutate(tags = reorder(tags, -Frequency))

 ggplot(tags_freq, aes(x = tags, y = Frequency)) +
  # Añade un gráfico de barras
   geom_bar(stat = "identity", aes(fill = Frequency)) +
   scale_y_continuous(labels = scales::percent) +
  # Aplica un tema predeterminado en blanco y negro para la visualización.
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Frequencia de tags", 
       x = "Tags",
       y = "Frecuencia ") + 
   scale_fill_gradient("Frecuencia", low = "skyblue", high = "coral2") +
   theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
tags_df <- data.frame(tags = unlist(tags_separados))

tags_freq <-tags_df %>%
  group_by(tags) %>%
  summarise(Frequency = n()) %>%
  mutate(Frequency = Frequency/ sum(Frequency)) %>%
  slice_min(Frequency, n=25) %>%
  mutate(tags = reorder(tags, -Frequency))

 ggplot(tags_freq, aes(x = tags, y = Frequency)) +
  # Añade un gráfico de barras
   geom_bar(stat = "identity", aes(fill = Frequency)) +
   scale_y_continuous(labels = scales::percent) +
  # Aplica un tema predeterminado en blanco y negro para la visualización.
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Frequencia de tags", 
       x = "Tags",
       y = "Frecuencia ") + 
   scale_fill_gradient("Frecuencia", low = "lightblue", high = "coral2") +
   theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


## Datos bivariantes

Vamos a comprobar diversas variables para ver si tienen relación entre ellas, tanto en el impacto en sus opiniones como en el mercado.

Empezamos comparando los tags con el año de salida para encontrar los más frecuentes según ha pasado el tiempo. Se continúa analizando las distintas tags con el tiempo de duración de cada juego. Una vez terminado con los tags, hablamos sobre cómo los años han afectado a las críticas oficiales y si los jugadores están de acuerdo con estas puntuaciones.

Por último, buscamos relaciones entre las reviews de críticos y jugadores con el tiempo de juego, en busca de una posible relación entre la longitud de un juego y su recibimiento en la industria. También se realiza el mismo análisis con los tags en vez de la duración de los juegos.

### Análisis de 'tags' y 'year'

A continuación, se comparará el año de salida de los juegos con el género de juego más producido cada año, seguido de un resumen en tabla de lo que dice el gráfico.

```{r}
# Paso 1: Separar los tags y mantener el año correspondiente
tags_separados <- datos %>%
  select(year, tags) %>%
  # Separar los tags en múltiples filas usando separate_rows
  separate_rows(tags, sep = "\\|")

# Paso 2: Contar las ocurrencias de cada tag por año
tags_por_año <- tags_separados %>%
  group_by(year, tags) %>%
  summarise(tag_count = n()) %>%
  ungroup()

# Paso 3: Filtrar los tags más frecuentes (opcional, por ejemplo, los 10 más frecuentes en total)
tags_mas_frecuentes <- tags_por_año %>%
  group_by(tags) %>%
  summarise(total_count = sum(tag_count)) %>%
  top_n(10, total_count)

# Paso 4: Filtrar los datos para mostrar solo los tags más frecuentes
tags_por_año_filtrado <- tags_por_año %>%
  filter(tags %in% tags_mas_frecuentes$tags)

# Paso 5: Graficar los tags más usados por año
ggplot(tags_por_año_filtrado, aes(x = year, y = tag_count, fill = tags)) +
  geom_bar(stat = "identity", position = "stack") +
  theme_minimal() +
  labs(title = "Tags más usados por año",
       x = "Año",
       y = "Frecuencia de tags",
       fill = "Tags") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


```{r}
# Paso 1: Filtrar los datos de los últimos 10 años
ultimo_año <- max(datos$year, na.rm = TRUE)  # Obtener el año más reciente
datos_ultimos_10_años <- datos %>%
  filter(year >= (ultimo_año - 9))  # Filtrar los últimos 10 años

# Paso 2: Separar los tags para cada año dentro de los últimos 10 años
tags_separados_ultimos_10_años <- datos_ultimos_10_años %>%
  select(year, tags) %>%
  separate_rows(tags, sep = "\\|")  # Separar los tags en filas individuales

# Paso 3: Agrupar por año y por tag, y contar la frecuencia de los tags por año
conteo_tags_ultimos_10_años <- tags_separados_ultimos_10_años %>%
  group_by(year, tags) %>%
  summarise(frecuencia = n()) %>%
  arrange(year, desc(frecuencia))  # Ordenar por año y frecuencia descendente

# Paso 4: Seleccionar el tag más usado por cada año en los últimos 10 años
tags_mas_usados_ultimos_10_años <- conteo_tags_ultimos_10_años %>%
  group_by(year) %>%
  slice_max(frecuencia, n = 1)  # Obtener el tag más usado para cada año

# Mostrar los tags más usados por año en los últimos 10 años
print(tags_mas_usados_ultimos_10_años)
```

###Análisis de 'tags' y tiempo de jugabilidad.

Ahora se realizará una comparativa entre los 25 tags más frecuentes y los diferentes tiempos (para completar la historia principal, el extra, y todos los objetivos del juego).


```{r}

datos$tags_freq <- sample(1:25, 63543, replace = TRUE)

# Filtrar valores por debajo de un umbral de 50 horas
datos_filtrados <- datos %>% filter(to_beat_main <= 50)

# Generar el boxplot con los datos filtrados
ggplot(datos_filtrados, aes(x = factor(tags_freq), y = to_beat_main)) + 
  geom_boxplot() +
  labs(x = "Tags más frecuentes", y = "To Beat Main", title = "Boxplot de To Beat Main por Tags más frecuentes") +
  theme_minimal()


```

El gráfico muestra que la mayoría de los juegos tienen un tiempo de finalización relativamente corto, por debajo de 10 horas. Los puntos son los valores atípicos.

```{r}

datos$tags_freq <- sample(1:25, 63543, replace = TRUE)

# Filtrar valores por debajo de un umbral de 50 horas
datos_filtrados <- datos %>% filter(to_beat_extra <= 50)

# Generar el boxplot con los datos filtrados
ggplot(datos_filtrados, aes(x = factor(tags_freq), y = to_beat_extra)) + 
  geom_boxplot() +
  labs(x = "Tags más frecuentes", y = "To Beat Extra", title = "Boxplot de To Beat Extra por Tags más frecuentes") +
  theme_minimal()


```

En este segundo gráfico se puede ver como los valores ascienden un poco estando entre las 15 y las 3 horas.
```{r}

datos$tags_freq <- sample(1:25, 63543, replace = TRUE)

# Filtrar valores por debajo de un umbral de 50 horas
datos_filtrados <- datos %>% filter(to_beat_completionist <= 50)

# Generar el boxplot con los datos filtrados
ggplot(datos_filtrados, aes(x = factor(tags_freq), y = to_beat_completionist)) + 
  geom_boxplot() +
  labs(x = "Tags más frecuentes", y = "To Beat Completionist", title = "Boxplot de To Beat Completionist por Tags más frecuentes") +
  theme_minimal()
```

Mientras que en este último ya podemos observar cómo los valores aumentan, pasando en algunos casos las 20 horas. Esto es de esperar, ya que "To Beat Completionist" incluye conseguir todos los logros del juego y no solo pasar la historia principal.

De estos tres gráficos, se puede ver claramente cómo el primero es el que más valores atípicos posee. Esto se puede atribuir a que se está comparando con el tiempo que se tarda en completar el juego completo. Mirando al gráfico, aunque lo más frecuente sea alrededor de las 10 horas, hay muchos valores atípicos que superan las 20 horas y llegan hasta las 50. Los otros dos gráficos están más igualados en el número de valores atípicos. También hay que destacar que "To Beat Extra", a pesar de tener juegos que duran más tiempo que "To Beat Main", tiene menos valores atípicos que se congregan alrededor de valores por encima de 30 horas y por debajo de 50.

### Análisis de 'year' y 'metacritic_rating'

Empezamos creando una tabla comparativa y calculando la covarianza y correlación:
```{r}
tabla_comparativa_años_criticas <- datos |> 
  filter(!is.na(year), !is.na(metacritic_rating)) |>  # Excluir NA
  mutate(rango_años = cut(year, breaks = 7),
         rango_criticas = cut(metacritic_rating, breaks = 7)) |> 
  count(rango_años, rango_criticas)

kable(tabla_comparativa_años_criticas)
```


Covarianza:
```{r}
cov_año_criticos <- cov(datos$year, datos$metacritic_rating, use = "complete.obs")
cov_año_criticos

```

Correlación:
```{r}
cor_año_criticos <- cor(datos$year, datos$metacritic_rating, use = "complete.obs")
cor_año_criticos

```
Este resultado indica que no hay una gran relación lineal pese a que la covarianza era bastante positiva y, aunque existe una leve tendencia a que las calificaciones de los críticos aumenten con los años debido a una mejora en la industria pues cada vez se crearían proyectos mejores que terminan gustando más, esta relación es muy débil y probablemente no significativa.

Gráfica de dispersión:
```{r}
ggplot(datos, aes(x = year, y = metacritic_rating, color = factor(tags_df))) +
  geom_point(color = "skyblue") +
  labs(x = "Año", y = "Valoración críticos") +
  ggtitle("Año vs. Valoración Críticos") +
  scale_color_discrete(name = "Tags")
```

Como es normal, podemos observar que hay mucha variedad en las valoraciones de los críticos ya que cada juego es diferente, sin embargo podemos ver ciertas tendencias sobre los años y, según los expertos, que años tuvieron "mejores" salidas en la industria. 

Tomamos en cuenta sobre todo los años de los que tenemos más datos y, tomando en cuenta que es una valoración sobre 100, desde el 2020 se percibe una supuesta mejora en las críticas, indicando que se han sacado al público mejores obras audiovisuales. Por el contrario, desde el 2009 hasta 2013 hubo una peor calidad.

Regresión lineal:

```{r}
datos |> 
  slice(1:100) |> 
  select(year, metacritic_rating) |> 
  ggplot(aes(x=year, y = metacritic_rating)) + 
  geom_point() + 
  theme_bw() + 
  geom_smooth(method = lm, se = FALSE)
```

Podemos determinar que la pendiente de la regresión lineal no es muy positiva, confirmando lo dicho con la correlación y covarianza.

```{r}
reg_año_critica <- lm(metacritic_rating ~ year, data = datos)
summary(reg_año_critica)
```
La regresión lineal sugiere que hay una relación positiva entre el año de lanzamiento del juego y su calificación por expertos, aunque la magnitud de esta relación es muy pequeña. Otros factores no considerados en esta sección del análisis podrían tener un mayor impacto en las calificaciones.


### Análisis de 'metacritic_rating' y 'rewiewer_rating'

Se va a comparar las puntuaciones de los críticos oficiales con la puntuación dada por los jugadores (reviewers).
Para ello se han seleccionado los 10 primeros juegos de la tabla, ignorando los juegos que no tenían valores de 'metacritic_rating' o 'rewiewer_rating'.

Gráfico de barras 'metacritic_rating' y 'rewiewer_rating':

```{r}

# Transformar los datos al formato largo, seleccionar los 10 primeros y ajustar metacritic_rating
datos_long <- datos %>%
  # Filtrar filas donde metacritic_rating o reviewer_rating son NA
  filter(!is.na(metacritic_rating) & !is.na(reviewer_rating)) %>%
  slice_head(n = 10) %>%
  mutate(metacritic_rating = metacritic_rating / 10) %>%  # Ajustar la puntuación a sobre 10
  pivot_longer(cols = c(metacritic_rating, reviewer_rating), 
               names_to = "tipo", 
               values_to = "valor") 

# Crear el gráfico de barras
ggplot(datos_long, aes(x = name, y = valor, fill = tipo)) +
  geom_bar(stat = "identity", position = position_dodge(), width = 0.7) +  # Ajustar ancho de barras
  labs(title = "Comparación de Metacritic y Reviewer Ratings",
       x = "Juegos",
       y = "Puntuaciones",
       fill = "Tipo") +
  scale_fill_manual(values = c("metacritic_rating" = "skyblue", "reviewer_rating" = "coral")) +  # Cambiar colores
  theme_minimal() +  # Cambiar a un tema minimalista
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotar etiquetas
       
```

Con esto se puede observar que ambas puntuaciones suelen tener valores muy cercanos, incluso iguales, exceptuando algunos casos como por ejemplo "Microsoft Flight Simulator", que ha sido mejor puntuado por los críticos, o "The Tiny Bang Story, que ha sido mejor puntuado por los jugadores.


También se ha realizado un gráfico de dispersión para visualizar mejor la correlación entre las dos puntuaciones.
```{r}
ggplot(datos, aes(x = metacritic_rating, y = reviewer_rating)) +
  geom_point(alpha = 0.5, color = "skyblue") +  # Puntos de color azul con algo de transparencia
  geom_smooth(method = "lm", color = "coral", se = FALSE) +  # Línea de tendencia lineal
  theme_minimal() +
  labs(title = "Comparación entre Metacritic Rating y Reviewer Rating",
       x = "Metacritic Rating (0-100)",
       y = "Reviewer Rating (0-10)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

La línea roja representa la correlación positiva que hay entre las dos puntuaciones, es decir, que suelen ser muy parecidas en la mayoría de los casos. Además podemos observar que la mayoría de los juegos suelen tener una puntuación de entre 5 y el 7.5.

### Análisis de 'reviewer_rating' y 'metacritic_rating' vs 'to_beat_main'

Se han realizado dos gráficos de dispersión para ver si había algún tipo de correlación entre la puntuación de los críticos y los reviewers, y el tiempo para completar un juego.

```{r}
# Filtrar los datos para mantener solo juegos con un tiempo de completar entre 0 y 100 horas
datos_filtrados <- datos %>%
  filter(to_beat_main >= 0 & to_beat_main <= 100)

# Gráfico de dispersión para comparar reviewer_rating y to_beat_main
ggplot(datos_filtrados, aes(x = to_beat_main, y = reviewer_rating)) +
  geom_point(alpha = 0.5, color = "skyblue") +  # Puntos de color azul con algo de transparencia
  geom_smooth(method = "lm", color = "coral", se = FALSE) +  # Línea de tendencia lineal
  theme_minimal() +
  labs(title = "Comparación entre Reviewer Rating y Tiempo para Completar el Juego Principal (0-100h)",
       x = "Tiempo para Completar el Juego Principal (horas)",
       y = "Reviewer Rating (0-10)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Correlación:
```{r}
cor_reviewer_main <- cor(datos$reviewer_rating, datos$to_beat_main, use = "complete.obs")
cor_reviewer_main

```

```{r}
# Filtrar los datos para mantener solo juegos con un tiempo de completar entre 0 y 100 horas
datos_filtrados <- datos %>%
  filter(to_beat_main >= 0 & to_beat_main <= 100)

# Gráfico de dispersión para comparar metacritic_rating y to_beat_main
ggplot(datos_filtrados, aes(x = to_beat_main, y = metacritic_rating)) +
  geom_point(alpha = 0.5, color = "skyblue") +  # Puntos de color azul con algo de transparencia
  geom_smooth(method = "lm", color = "coral", se = FALSE) +  # Línea de tendencia lineal
  theme_minimal() +
  labs(title = "Comparación entre Metacritic Rating y Tiempo para Completar el Juego Principal (0-100h)",
       x = "Tiempo para Completar el Juego Principal (horas)",
       y = "Metacritic Rating (0-100)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Correlación:
```{r}
cor_metacritic_main <- cor(datos$metacritic_rating, datos$to_beat_main, use = "complete.obs")
cor_metacritic_main

```
Se puede observar en ambos casos que la correlación es muy baja tendiendo a cero por lo que no hay evidencia de que el tiempo en completar el juego principal tenga un impacto significativo en la puntuación de Metacritic o Reviewer Rating. Ambos gráficos tienen juegos con muy buenas puntuaciones que no tienen muchas horas de juego, lo mismo con muchas horas. No hay un patrón distinguible y se puede concluir que el tiempo no es una variable decisiva.


### Análisis de 'tags' y 'reviewer_rating'

Ya que se dispone de dos variables distintas para medir la satisfacción del público, el análisis anterior se repetirá ahora con las puntuaciones de los usuarios, 'reviewer_rating'. No obstante, dado que ya se ha estudiado ambas variables de puntuación entre sí y obteniendo como resultado que no difieren significativamente, se espera que los resultados en comparación al apartado anterior apeans varíen.

Para estudiar ambas variables se seguirá el mismo camino que en el apartado anterior. Primeramente, creando un resumen estadístico de ambas:


```{r}
datos_separados <- datos %>%
  separate_rows(tags, sep = "\\|") %>%  # Separar tags por coma
  mutate(tags = str_trim(tags))  # Eliminar espacios adicionales

# Paso 2: Agrupar por los tags separados y calcular el resumen
resumen_tags <- datos_separados %>%
  group_by(tags) %>%
  summarise(
    mean_rating = mean(reviewer_rating, na.rm = TRUE),  # Media de la nota
    n = n()  # Número de juegos con cada tag
  ) %>%
  arrange(desc(mean_rating))  # Ordenar por la media

# Imprimir el resumen
print(resumen_tags)
```

Posteriormente se representará esto mismo visualnmente con ayuda de un gráfico de box plots:

```{r}
# Paso 1: Separar los tags por el carácter '|' y eliminar espacios adicionales
datos_separados <- datos %>%
  separate_rows(tags, sep = "\\|") %>%  # Separar por '|'
  mutate(tags = str_trim(tags))  # Eliminar espacios en blanco adicionales

# Paso 2: Filtrar los tags más comunes (aquellos con más de 10 juegos)
tags_comunes <- datos_separados %>%
  count(tags) %>%  # Contar la frecuencia de cada tag
  filter(n > 10) %>%  # Filtrar solo los tags con más de 10 juegos
  pull(tags)  # Extraer la lista de tags comunes

# Paso 3: Crear el boxplot con los tags más comunes
ggplot(datos_separados %>% filter(tags %in% tags_comunes), aes(x = tags, y = reviewer_rating)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotar etiquetas de los tags
  labs(title = "Distribución de Reviewer Rating por Tags", x = "Tags", y = "Reviewer Rating")


```

Tal y como ocurría en el caso anterior, al disponer de tantos 'tags' resulta imposible analizarlo de este modo, por lo que, de nuevo, se analizarán únicamente los 15 'tags' más frecuentes:

```{r}
datos_separados <- datos %>%
  separate_rows(tags, sep = "\\|") %>%  # Separar los tags por '|'
  mutate(tags = str_trim(tags))  # Eliminar espacios en blanco adicionales

# Paso 2: Obtener los 15 tags más comunes
tags_comunes <- datos_separados %>%
  count(tags) %>%  # Contar la frecuencia de cada tag
  top_n(15, n) %>%  # Seleccionar los 15 tags más comunes
  pull(tags)  # Extraer la lista de los tags comunes

# Paso 3: Crear boxplots separados para los 15 tags más comunes
ggplot(datos_separados %>% filter(tags %in% tags_comunes), 
       aes(x = reviewer_rating)) +  # Eje x es el reviewer_rating
  geom_boxplot() +
  facet_wrap(~ tags, scales = "free", ncol = 3) +  # Crear facetas por tag, 3 columnas
  labs(title = "Distribución de Reviewer Rating por los 15 Tags Más Comunes", 
       x = "Reviewer Rating", 
       y = "Tags") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),  # Etiquetas del eje x en vertical
        plot.margin = margin(10, 10, 10, 20))
```
 


# Conclusión 

Habiendo analizado todas las relaciones que nos habíamos propuesto y en las que podíamos encontrar una utilidad para analizar el mercado, nos hemos encontrado con diversos factores sobre las tendencias de las últimas décadas. Empezando con los tags, se puede ver un claro favoritismo hacia el tag de juego "Indie" durante todo el 2014 hasta el 2020, siendo sustituido en los últimos años por "Singleplayer". Al analizar cómo se comportan los tags más frecuentes al ser enfrentados con la duración de sus contenidos, se puede ver cómo se tiende a realizar juegos de entre 3 y 15 horas.

A través de las tablas y correlaciones de cómo las críticas han ido cambiando según los años, se puede determinar que hay una relación entre ambos factores, aunque sea pequeña. Con ello, llegamos a la conclusión de que, a medida que ha avanzado la industria, factores como la imagen o calidad final del producto visual han ido cobrando más importancia gracias a las mejoras en las consolas y ordenadores. Por otro lado, también hemos visto cómo la puntuación de los jugadores es similar a la de Metacritic y el parecido entre ambas; además, también comparten la nula influencia que posee la duración del juego en su nota.

En conclusión:

- Los juegos con los tags más frecuentes tienden a durar alrededor de 15 horas. Esto se podría justificar con que uno de los tags más frecuentes es "Indie", que es normalmente usado para referirse a estudios pequeños que trabajan con menos presupuesto y sacan producciones más cortas.

- La duración de los juegos no influye en el recibimiento de este.

- Ha subido la dependencia entre buenas reviews con el tiempo, justificando así la necesidad de producir buenos gráficos.

- La opinión de Metacritic y de los jugadores comparten similitudes y son compatibles en un rango aceptable.


Github del proyecto: https://github.com/irenetm17/EstadisticaMomento
